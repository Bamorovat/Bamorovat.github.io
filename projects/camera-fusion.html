<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="description" content="Real-time Camera Fusion System for Autonomous Vehicles">
    <title>Camera Fusion for AV Project - Mohammad Hossein Bamorovat Abadi</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/css/main.css">
    <style>
        .project-hero {
            background: linear-gradient(135deg, #059669 0%, #06d6a0 100%);
            color: white;
            padding: 4rem 0;
            text-align: center;
        }
        .project-hero h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
        }
        .project-hero p {
            font-size: 1.2rem;
            opacity: 0.9;
            max-width: 800px;
            margin: 0 auto;
        }
        .back-button {
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 2rem;
            color: var(--primary-color);
            text-decoration: none;
            font-weight: 500;
        }
        .back-button:hover {
            text-decoration: underline;
        }
        .project-content {
            max-width: 1000px;
            margin: 0 auto;
            padding: 3rem 2rem;
        }
        .fusion-diagram {
            background: var(--section-bg);
            padding: 2rem;
            border-radius: 12px;
            text-align: center;
            margin: 2rem 0;
        }
        .camera-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }
        .camera-card {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            box-shadow: var(--card-shadow);
            text-align: center;
            border-top: 3px solid var(--accent-color);
        }
        .performance-stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }
        .stat-card {
            background: var(--section-bg);
            padding: 1.5rem;
            border-radius: 8px;
            text-align: center;
            border-left: 4px solid var(--primary-color);
        }
        .stat-number {
            font-size: 2rem;
            font-weight: 700;
            color: var(--primary-color);
            display: block;
        }
    </style>
</head>
<body>
    <div class="project-hero">
        <div class="hero-content">
            <h1><i class="fas fa-video"></i> Real-time Camera Fusion for AV</h1>
            <p>Advanced multi-camera fusion and stitching system providing 360-degree environmental awareness for autonomous vehicles</p>
        </div>
    </div>

    <div class="project-content">
        <a href="../index.html#projects" class="back-button">
            <i class="fas fa-arrow-left"></i> Back to Projects
        </a>

        <div class="card">
            <h2>Project Overview</h2>
            <p>
                The Real-time Camera Fusion system for Autonomous Vehicles is an advanced perception solution developed at Conigital that combines multiple camera feeds into a unified, comprehensive view of the vehicle's environment. This system enables autonomous vehicles to have complete 360-degree situational awareness through sophisticated image processing and fusion techniques.
            </p>
            
            <h3>Development Context</h3>
            <p>
                This project was developed as part of my work as a Perception Engineer at Conigital, focusing on creating robust perception systems for autonomous vehicles. The system addresses the critical need for comprehensive environmental awareness in autonomous driving scenarios.
            </p>
        </div>

        <div class="card">
            <h2>System Architecture</h2>
            <div class="fusion-diagram">
                <i class="fas fa-car" style="font-size: 3rem; color: var(--primary-color); margin-bottom: 1rem;"></i>
                <p><strong>Multi-Camera Fusion Architecture</strong></p>
                <p>Real-time integration of multiple camera feeds into a unified perception system</p>
            </div>
            
            <h3>Camera Configuration</h3>
            <div class="camera-grid">
                <div class="camera-card">
                    <i class="fas fa-arrow-up" style="font-size: 2rem; color: var(--accent-color); margin-bottom: 0.5rem;"></i>
                    <h4>Front Camera</h4>
                    <p>Primary forward-facing perception</p>
                </div>
                <div class="camera-card">
                    <i class="fas fa-arrow-down" style="font-size: 2rem; color: var(--accent-color); margin-bottom: 0.5rem;"></i>
                    <h4>Rear Camera</h4>
                    <p>Backward monitoring and parking assistance</p>
                </div>
                <div class="camera-card">
                    <i class="fas fa-arrow-left" style="font-size: 2rem; color: var(--accent-color); margin-bottom: 0.5rem;"></i>
                    <h4>Left Camera</h4>
                    <p>Left-side blind spot coverage</p>
                </div>
                <div class="camera-card">
                    <i class="fas fa-arrow-right" style="font-size: 2rem; color: var(--accent-color); margin-bottom: 0.5rem;"></i>
                    <h4>Right Camera</h4>
                    <p>Right-side blind spot coverage</p>
                </div>
                <div class="camera-card">
                    <i class="fas fa-circle" style="font-size: 2rem; color: var(--accent-color); margin-bottom: 0.5rem;"></i>
                    <h4>Additional Cameras</h4>
                    <p>Corner and specialty view cameras</p>
                </div>
            </div>
        </div>

        <div class="card">
            <h2>Key Features</h2>
            
            <h3>Real-time Processing</h3>
            <ul>
                <li><strong>Low Latency:</strong> Minimal processing delay for real-time decision making</li>
                <li><strong>High Throughput:</strong> Processing multiple camera feeds simultaneously</li>
                <li><strong>Optimized Algorithms:</strong> Efficient fusion algorithms for automotive hardware</li>
            </ul>
            
            <h3>Image Stitching & Fusion</h3>
            <ul>
                <li><strong>Seamless Blending:</strong> Smooth transitions between camera views</li>
                <li><strong>Geometric Correction:</strong> Lens distortion and perspective correction</li>
                <li><strong>Color Calibration:</strong> Consistent color balance across all cameras</li>
                <li><strong>Dynamic Exposure:</strong> Adaptive exposure compensation for varying lighting</li>
            </ul>
            
            <h3>Environmental Awareness</h3>
            <ul>
                <li><strong>360° Coverage:</strong> Complete surrounding environment monitoring</li>
                <li><strong>Blind Spot Elimination:</strong> No visual dead zones around the vehicle</li>
                <li><strong>Depth Perception:</strong> Stereo processing for distance estimation</li>
                <li><strong>Object Detection Integration:</strong> Compatible with AI detection systems</li>
            </ul>
        </div>

        <div class="card">
            <h2>Performance Specifications</h2>
            <div class="performance-stats">
                <div class="stat-card">
                    <span class="stat-number">30+</span>
                    <div>FPS Processing</div>
                </div>
                <div class="stat-card">
                    <span class="stat-number">&lt;50ms</span>
                    <div>Latency</div>
                </div>
                <div class="stat-card">
                    <span class="stat-number">360°</span>
                    <div>Field of View</div>
                </div>
                <div class="stat-card">
                    <span class="stat-number">4K</span>
                    <div>Resolution Support</div>
                </div>
                <div class="stat-card">
                    <span class="stat-number">6+</span>
                    <div>Camera Inputs</div>
                </div>
                <div class="stat-card">
                    <span class="stat-number">99%</span>
                    <div>Uptime</div>
                </div>
            </div>
        </div>

        <div class="card">
            <h2>Technical Implementation</h2>
            
            <h3>Image Processing Pipeline</h3>
            <ol>
                <li><strong>Camera Calibration:</strong> Intrinsic and extrinsic parameter estimation</li>
                <li><strong>Distortion Correction:</strong> Lens distortion removal and geometric correction</li>
                <li><strong>Feature Detection:</strong> Keypoint detection for image alignment</li>
                <li><strong>Image Registration:</strong> Geometric transformation and alignment</li>
                <li><strong>Blending & Stitching:</strong> Seamless image combination</li>
                <li><strong>Post-processing:</strong> Color correction and enhancement</li>
            </ol>
            
            <h3>Fusion Algorithms</h3>
            <ul>
                <li><strong>Homography Estimation:</strong> Robust geometric transformation calculation</li>
                <li><strong>Multi-band Blending:</strong> Frequency-domain image blending</li>
                <li><strong>Real-time Optimization:</strong> GPU-accelerated processing</li>
                <li><strong>Adaptive Parameters:</strong> Dynamic adjustment based on conditions</li>
            </ul>
        </div>

        <div class="card">
            <h2>Sample Outcomes</h2>
            <div class="fusion-diagram">
                <i class="fas fa-images" style="font-size: 3rem; color: var(--secondary-color); margin-bottom: 1rem;"></i>
                <p><strong>Fusion Results</strong></p>
                <p>Sample images showing the quality and effectiveness of the camera fusion system</p>
                <p><em>Before and after fusion comparisons demonstrating the system's capabilities</em></p>
            </div>
            
            <h3>Available Resources</h3>
            <ul>
                <li><strong>Complete Source Code:</strong> Full implementation of the fusion system</li>
                <li><strong>Calibration Tools:</strong> Camera calibration and setup utilities</li>
                <li><strong>Performance Benchmarks:</strong> Detailed performance analysis and optimization</li>
                <li><strong>Integration Documentation:</strong> Vehicle integration guidelines and APIs</li>
            </ul>
        </div>

        <div class="card">
            <h2>Applications & Benefits</h2>
            
            <h3>Autonomous Vehicle Applications</h3>
            <ul>
                <li><strong>Path Planning:</strong> Enhanced environmental understanding for navigation</li>
                <li><strong>Obstacle Detection:</strong> Comprehensive object detection and avoidance</li>
                <li><strong>Parking Assistance:</strong> 360-degree view for precise maneuvering</li>
                <li><strong>Safety Monitoring:</strong> Continuous surveillance of vehicle surroundings</li>
            </ul>
            
            <h3>System Benefits</h3>
            <ul>
                <li><strong>Enhanced Safety:</strong> Complete situational awareness reduces accidents</li>
                <li><strong>Improved Performance:</strong> Better decision-making through comprehensive data</li>
                <li><strong>Cost Effective:</strong> Camera-based solution vs. expensive sensor alternatives</li>
                <li><strong>Scalable:</strong> Adaptable to different vehicle types and configurations</li>
            </ul>
        </div>

        <div class="card">
            <h2>GitHub Repository & Implementation</h2>
            <p>
                Access the complete ROS-based implementation of the panoramic camera fusion system, including calibration algorithms, real-time stitching pipelines, and optimization techniques for autonomous vehicle applications.
            </p>
            
            <div class="project-links" style="margin-top: 1.5rem;">
                <a href="https://github.com/Bamorovat/Panorama-Ros" target="_blank" class="btn btn-primary" style="margin-right: 1rem;">
                    <i class="fab fa-github"></i> View Source Code
                </a>
                <a href="https://github.com/Bamorovat/Panorama-Ros#readme" target="_blank" class="btn btn-outline">
                    <i class="fas fa-book"></i> Documentation
                </a>
            </div>
            
            <div style="margin-top: 1rem; padding: 1rem; background: var(--card-bg); border-radius: 8px; border: 1px solid var(--border-color);">
                <p style="margin: 0; font-size: 0.9rem; color: var(--text-secondary);">
                    <i class="fas fa-info-circle"></i> 
                    <strong>Repository Features:</strong> Complete ROS package for multi-camera fusion, panoramic image stitching, real-time processing optimizations, calibration utilities, and integration modules for autonomous vehicle perception systems.
                </p>
            </div>
        </div>

        <div class="card" style="text-align: center;">
            <h2>Project Impact</h2>
            <p>
                The Real-time Camera Fusion system significantly enhances autonomous vehicle perception capabilities by providing comprehensive environmental awareness through advanced image processing and fusion techniques. This system contributes to safer and more reliable autonomous driving operations.
            </p>
            
            <div style="margin-top: 2rem;">
                <a href="mailto:mohammad.bamorovatAbadi@manchester.ac.uk" class="btn btn-primary">
                    <i class="fas fa-envelope"></i> Discuss Technology
                </a>
                <a href="../index.html#projects" class="btn btn-outline" style="margin-left: 1rem;">
                    <i class="fas fa-arrow-left"></i> Back to Projects
                </a>
            </div>
        </div>
    </div>

    <script>
        // Smooth scroll for navigation
        document.addEventListener('DOMContentLoaded', function() {
            const backButton = document.querySelector('.back-button');
            if (backButton) {
                backButton.addEventListener('click', function(e) {
                    e.preventDefault();
                    window.location.href = '../index.html#projects';
                });
            }
        });
    </script>
</body>
</html>
